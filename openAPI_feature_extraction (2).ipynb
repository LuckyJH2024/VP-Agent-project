{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHbwBMHBWIQH"
      },
      "outputs": [],
      "source": [
        "# ✅ 适配 OpenAI API，用于大文本分块处理\n",
        "import openai\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ✅ 1. 设置 OpenAI API Key（推荐使用环境变量，避免泄露）\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ✅ 2. 读取医学文本（逐块读取，防止超时）\n",
        "file_path = \"/content/Plumbs Veterinary Drug Handbook (Donald C. Plumb) (Z-Library) .txt\"\n",
        "chunk_size = 10000  # 每次处理 3000 字符\n",
        "all_medicines = []  # 存储所有药物数据\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    while True:\n",
        "        chunk = f.read(chunk_size)\n",
        "        if not chunk:\n",
        "            break  # 读取完成，退出循环\n",
        "\n",
        "        # ✅ 3. 构建 Prompt（确保 GPT 严格输出 JSON）\n",
        "        prompt = f\"\"\"\n",
        "        你是一位专业的宠物医学和药物信息解析助手。请从以下医学文本中提取 **结构化药物信息**，包括：\n",
        "        - **药物名称 (Medicine Name)**\n",
        "        - **适应症 (UseCase)**\n",
        "        - **禁忌 (Contraindications)**\n",
        "        - **副作用 (SideEffects)**\n",
        "        - **药理作用 (Pharmacology)**\n",
        "\n",
        "        请严格按照 **JSON 格式** 返回，示例如下：\n",
        "        ```json\n",
        "        [\n",
        "          {{\n",
        "            \"药物名称\": \"ACARBOSE\",\n",
        "            \"适应症\": [\"用于糖尿病控制\"],\n",
        "            \"禁忌\": [\"孕妇禁用\", \"对阿卡波糖过敏者禁用\"],\n",
        "            \"副作用\": [\"胃肠道不适\", \"腹胀\"],\n",
        "            \"药理作用\": [\"延缓碳水化合物的消化吸收\"]\n",
        "          }},\n",
        "          ...\n",
        "        ]\n",
        "        ```\n",
        "        **请直接返回 JSON，不要有额外的说明**。\n",
        "\n",
        "        以下是医学文本：\n",
        "        ```text\n",
        "        {chunk}\n",
        "        ```\n",
        "        \"\"\"\n",
        "\n",
        "        # ✅ 4. 发送请求到 OpenAI GPT\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"你是专业的医学药物信息提取助手。\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.3  # 降低随机性，提高输出稳定性\n",
        "            )\n",
        "\n",
        "            # ✅ 5. 解析 GPT 结果（JSON 解析）\n",
        "            gpt_response = response.choices[0].message.content.strip()\n",
        "            parsed_data = json.loads(gpt_response)\n",
        "\n",
        "            # ✅ 6. 合并当前块的数据\n",
        "            all_medicines.extend(parsed_data)\n",
        "            print(f\"✅ 处理完成 {len(parsed_data)} 条药物数据，目前总数: {len(all_medicines)}\")\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"⚠ 解析 JSON 失败，可能 GPT 输出格式有误，跳过此部分！\")\n",
        "            print(\"🔥 GPT 输出内容：\")\n",
        "            print(gpt_response)  # 打印 GPT 输出，方便调试\n",
        "            continue  # 继续处理下一块数据\n",
        "\n",
        "# ✅ 7. 转换为 DataFrame 并展示部分数据\n",
        "df_gpt = pd.DataFrame(all_medicines[:5])  # 仅展示前 5 条数据\n",
        "\n",
        "# ✅ 8. 保存 JSON 文件\n",
        "output_json = \"parsed_medicine_data.json\"\n",
        "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(all_medicines, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✅ 所有药物信息已提取完成，数据已保存到 {output_json}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kyaRz4w3aDY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 适配 Google Colab，分块读取大文件\n",
        "import openai\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# ✅ 让 Colab 兼容 asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ✅ 1. 设置 OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ✅ 2. 读取医学文本（分块读取，防止内存溢出）\n",
        "file_path = \"Plumbs Veterinary Drug Handbook (Donald C. Plumb) (Z-Library).txt\"\n",
        "chunk_size = 10000  # 每次读取 10000 字符\n",
        "\n",
        "def process_chunk(chunk_text):\n",
        "    \"\"\"同步调用 GPT 处理文本块（修复 await 兼容性）\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    你是一位专业的宠物医学和药物信息解析助手。请从以下医学文本中提取 **结构化药物信息**，包括：\n",
        "    - **药物名称 (Medicine Name)**\n",
        "    - **适应症 (UseCase)**\n",
        "    - **禁忌 (Contraindications)**\n",
        "    - **副作用 (SideEffects)**\n",
        "    - **药理作用 (Pharmacology)**\n",
        "\n",
        "    请严格按照 **JSON 格式** 返回，例如：\n",
        "    [\n",
        "      {{\n",
        "        \"药物名称\": \"ACARBOSE\",\n",
        "        \"适应症\": [\"用于糖尿病控制\"],\n",
        "        \"禁忌\": [\"孕妇禁用\", \"对阿卡波糖过敏者禁用\"],\n",
        "        \"副作用\": [\"胃肠道不适\", \"腹胀\"],\n",
        "        \"药理作用\": [\"延缓碳水化合物的消化吸收\"]\n",
        "      }},\n",
        "      {{\n",
        "        \"药物名称\": \"...\",\n",
        "        \"适应症\": [...],\n",
        "        \"禁忌\": [...],\n",
        "        \"副作用\": [...],\n",
        "        \"药理作用\": [...]\n",
        "      }}\n",
        "    ]\n",
        "\n",
        "    **请直接返回 JSON，不要有额外的说明**。\n",
        "\n",
        "    以下是医学文本：\n",
        "    {chunk_text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"你是专业的医学药物信息提取助手。\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        gpt_response = response.choices[0].message.content\n",
        "        parsed_data = json.loads(gpt_response)\n",
        "        return parsed_data\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ GPT 解析失败:\", e)\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    \"\"\"同步读取大文本文件并解析\"\"\"\n",
        "    all_medicines = []\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)  # 读取部分内容\n",
        "            if not chunk:\n",
        "                break  # 读完就退出循环\n",
        "\n",
        "            medicines = process_chunk(chunk)  # 发送到 GPT 处理\n",
        "            all_medicines.extend(medicines)  # 汇总所有解析数据\n",
        "\n",
        "            print(f\"✅ 处理完成 {len(all_medicines)} 种药物\")\n",
        "\n",
        "    # ✅ 4. 转换为 DataFrame\n",
        "    df_gpt = pd.DataFrame(all_medicines)\n",
        "\n",
        "    # ✅ 5. 保存 JSON 文件\n",
        "    output_json = \"parsed_medicine_data.json\"\n",
        "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(all_medicines, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"✅ 所有药物信息已提取完成，共提取 {len(all_medicines)} 条数据，数据已保存到 {output_json}\")\n",
        "\n",
        "# ✅ 运行主任务\n",
        "main()\n"
      ],
      "metadata": {
        "id": "jpRd_xmzceI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aaAWLgJhd2Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tOAWR8R6lLD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IL0o4MT6vIRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IB_b7HSmvOng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "i_CsxtPDJ0LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fFUdrduNwHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ZLhzhExT6Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ng2ctr98OGFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6V4hv2M90gEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "6qdThXSfMH1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "q2c2oLYdU-Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxNPbE9oOsda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_text)"
      ],
      "metadata": {
        "id": "J-EwbxYFQJit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqOpxAjuR60B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yeZf-bSfaFsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DhmuPWfa4Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DtJxognr98D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qyYb8FpcjMse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjJQDigFGhMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}